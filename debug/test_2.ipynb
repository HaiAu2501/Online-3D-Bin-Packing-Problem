{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from env.env import BinPacking3DEnv\n",
    "from models.transformer import BinPackingTransformer\n",
    "from models.policy_net import PolicyNetwork\n",
    "from models.value_net import ValueNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST: Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transformer model\n",
    "transformer = BinPackingTransformer(\n",
    "\td_model=128,\n",
    "\tn_head=8,\n",
    "\tn_layers=3,\n",
    "\td_feedforward=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinPackingTransformer(\n",
       "  (ems_list_embedding): Embedding(\n",
       "    (linear): Linear(in_features=6, out_features=128, bias=True)\n",
       "  )\n",
       "  (buffer_embedding): Embedding(\n",
       "    (linear): Linear(in_features=3, out_features=128, bias=True)\n",
       "  )\n",
       "  (transformer_blocks): ModuleList(\n",
       "    (0-2): 3 x TransformerBlock(\n",
       "      (self_attn_ems_list): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (self_attn_buffer): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (norm1_ems_list): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm1_buffer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_ems_list): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "      (mlp_buffer): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "      (norm2_ems_list): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2_buffer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (cross_attn_ems_list): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (cross_attn_buffer): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (norm3_ems_list): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3_buffer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_final_ems_list): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "      (mlp_final_buffer): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "      (norm4_ems_list): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm4_buffer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (combined_pooling): CombinedPooling(\n",
       "    (attn): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (pooling_linear): Linear(in_features=384, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2430081"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in transformer.parameters())\n",
    "\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an environment and dummy input to test the model\n",
    "env = BinPacking3DEnv(\n",
    "\tbin_size=(5, 5, 5),\n",
    "\titems=[(2, 3, 1), (2, 2, 3), (1, 1, 2), (3, 2, 2)],\n",
    "\tbuffer_size=2,\n",
    "\tnum_rotations=2,\n",
    "\tmax_ems=100,\n",
    ")\n",
    "\n",
    "obervation = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EMS list\n",
    "ems_list = obervation['ems_list']\n",
    "\n",
    "ems_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EMS mask\n",
    "ems_mask = obervation['ems_mask']\n",
    "\n",
    "ems_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buffer\n",
    "buffer = obervation['buffer']\n",
    "\n",
    "buffer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 100, 6), (1, 100), (1, 2, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand the dimensions of the input to match the model's input shape\n",
    "ems_list_np = np.expand_dims(ems_list, axis=0)  # [1, max_ems, 6]\n",
    "ems_mask_np = np.expand_dims(ems_mask, axis=0)  # [1, max_ems]\n",
    "buffer_np = np.expand_dims(buffer, axis=0)      # [1, buffer_size, 3]\n",
    "\n",
    "ems_list_np.shape, ems_mask_np.shape, buffer_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 100, 6]), torch.Size([1, 100]), torch.Size([1, 2, 3]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the numpy arrays to tensors\n",
    "ems_list_tensor = torch.tensor(ems_list_np, dtype=torch.float32)\n",
    "ems_mask_tensor = torch.tensor(ems_mask_np, dtype=torch.bool)\n",
    "buffer_tensor = torch.tensor(buffer_np, dtype=torch.float32)\n",
    "\n",
    "\n",
    "ems_list_tensor.shape, ems_mask_tensor.shape, buffer_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the device to run the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model and input tensors to the device\n",
    "transformer.to(device)\n",
    "\n",
    "ems_list_tensor = ems_list_tensor.to(device)\n",
    "ems_mask_tensor = ems_mask_tensor.to(device)\n",
    "buffer_tensor = buffer_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 128]), torch.Size([1, 128]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "transformer.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\tems_list_features, buffer_features = transformer(\n",
    "\t\tems_list=ems_list_tensor,\n",
    "\t\tbuffer=buffer_tensor,\n",
    "\t\tems_mask=ems_mask_tensor,\n",
    "\t)\n",
    "\n",
    "ems_list_features.shape, buffer_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST: Value Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_net = ValueNetwork(\n",
    "\td_input=128,\n",
    "\td_hidden=128,\n",
    ")\n",
    "\n",
    "value_net.to(device)\n",
    "\n",
    "value_net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\tvalue = value_net(ems_list_features, buffer_features)\n",
    "\n",
    "value.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST: Policy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 2, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the action mask\n",
    "action_mask = obervation['action_mask'] # [W, L, num_rotations, buffer_size]\n",
    "\n",
    "action_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 5, 2, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand the dimensions of the action mask to match the model's input shape\n",
    "action_mask_np = np.expand_dims(action_mask, axis=0)  # [batch_size=1, W, L, num_rotations, buffer_size]\n",
    "action_mask_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 5, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the numpy array to a tensor\n",
    "action_mask_tensor = torch.tensor(action_mask_np, dtype=torch.bool) # [batch_size=1, W, L, num_rotations, buffer_size]\n",
    "\n",
    "action_mask_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the action mask tensor\n",
    "action_mask_tensor = action_mask_tensor.reshape(1, -1)  # [batch_size=1, W * L * num_rotations * buffer_size]\n",
    "\n",
    "action_mask_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net = PolicyNetwork(\n",
    "\td_action=5*5*2*2,\n",
    "\td_input=128,\n",
    "\td_hidden=128,\n",
    ")\n",
    "\n",
    "policy_net.to(device)\n",
    "action_mask_tensor = action_mask_tensor.to(device)\n",
    "\n",
    "policy_net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\tpolicy = policy_net(ems_list_features, buffer_features, action_mask_tensor)\n",
    "\n",
    "policy.shape # [batch_size=1, W * L * num_rotations * buffer_size]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
